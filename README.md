# Video-SA-intro
Samples of Video-SA (Video Data for Multimodal Sentiment Analysis)

The data set contains nearly a thousand pieces of emotions video data, each of which is 30s (split into 10s each), from major film and television dramas. This data set is mainly used for multi-modal sentiment analysis. Images, speech and text modalities can be extracted from each video. The sentiment label not only contains the traditional 6 emotions: "happy", "sad", "angry", "disgust", "fear", and "surprise". It also includes complex emotions and advanced rhetoric such as "sarcasm", "self-deprecating", and "simile" (but labeled with main emotions). We have written and contributed a multi-modal emotional computing paper. After subsequent publication, we will open source the project code and manually mark the information.

The dataset has 1350 RGB videos of 240 frames, with 675 sentiment data and 675 normal data, and be divided into two parts. The first part is collected from 5 volunteers in the 15 contexts (each person makes 5 videos in each context, $5 \times 15 \times 5 = 375$ in total). The second part is collected from hit TV series (e.g., 2 Broke Girls, The Big Bang, etc.), with 300 videos in the 15 contexts (each contains 20 samples). For the former, we designed 5 long dialogue scenes (including text content, voice intonation and facial expressions) for each context according to the IEMOCAP and MUStARD datasets. 5 volunteers were filmed under natural light conditions. For the latter, we crawled 800 open copyright video clips from websites such as youtube, finally obtained 300 videos in 15 contexts.


samples of this dataset will be upload before 2023.

